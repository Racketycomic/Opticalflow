{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitching up the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "img_files = sorted(glob.glob('YCBvideo/data/0001/*.jpg'))\n",
    "sample_img = cv.imread(img_files[0])\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "h,w,l = sample_img.shape\n",
    "video = cv.VideoWriter('sample1.mp4',fourcc,1,(w,h),True)\n",
    "for img in img_files:\n",
    "    i= cv.imread(img)\n",
    "    video.write(i)\n",
    "    \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playing with corner detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv as cv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the image and convert to grayscale\n",
    "frame = cv.imread('YCBvideo/data/0001/000001-color.jpg')\n",
    "frame2 = cv.imread('YCBvideo/data/0001/000001-color.jpg')\n",
    "\n",
    "bounding_box_df = pd.read_csv('YCBvideo/data/0001/000001-box.txt',sep=' ',header=None)\n",
    "df = bounding_box_df.iloc[0]\n",
    "padding = 0\n",
    "x_min ,x_max ,y_min, y_max = int(df[1])+padding,int(df[2])+padding,int(df[3])+padding,int(df[4]+padding)\n",
    "x_min ,x_max ,y_min, y_max\n",
    "\n",
    "cv.rectangle(frame2,(x_min,y_min),(x_max,y_max),(0,255,0),2)\n",
    "cv.imshow('im',frame2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 [0 1 2 3 5] (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "frame = cv.imread('YCBvideo/data/0001/000001-label.png')\n",
    "print(np.min(frame),np.max(frame),np.unique(frame),frame.shape)\n",
    "o1 = np.zeros_like(frame)\n",
    "o1[frame==1] = 255\n",
    "cv.imshow('mask',o1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray_frame = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "mask = np.zeros_like(gray_frame)\n",
    "mask[y_min:y_max,x_min:x_max] = 255\n",
    "\n",
    "\n",
    "feature_params = dict(maxCorners=20, qualityLevel=0.5, minDistance=8, blockSize=10)\n",
    "corners = cv.goodFeaturesToTrack(gray_frame, mask=mask ,**feature_params)\n",
    "for i in corners:\n",
    "    x, y = i.ravel()\n",
    "    cv.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "# Display the image with corners marked\n",
    "cv.imshow('Corners', frame)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640) (480, 640)\n",
      "[  0 255]\n",
      "[[[293.25668 140.8232 ]]\n",
      "\n",
      " [[270.34924 143.85898]]\n",
      "\n",
      " [[255.42058 153.94127]]\n",
      "\n",
      " [[164.41548 178.97842]]\n",
      "\n",
      " [[284.3657  230.99585]]\n",
      "\n",
      " [[258.3537  145.85437]]\n",
      "\n",
      " [[247.33624 147.91739]]\n",
      "\n",
      " [[204.41205 195.91687]]\n",
      "\n",
      " [[278.43625 179.90427]]\n",
      "\n",
      " [[255.3555  197.93575]]\n",
      "\n",
      " [[215.43845 237.94972]]\n",
      "\n",
      " [[269.39868 184.83138]]\n",
      "\n",
      " [[270.4101  191.85257]]\n",
      "\n",
      " [[275.31274 138.87344]]\n",
      "\n",
      " [[296.33286 188.87415]]\n",
      "\n",
      " [[211.23651 172.92563]]\n",
      "\n",
      " [[276.42566 211.93138]]\n",
      "\n",
      " [[284.30203 141.84187]]\n",
      "\n",
      " [[301.378   201.91818]]\n",
      "\n",
      " [[312.3365  148.87537]]\n",
      "\n",
      " [[233.21907 161.94226]]\n",
      "\n",
      " [[255.34962 190.94832]]\n",
      "\n",
      " [[309.32968 185.88972]]\n",
      "\n",
      " [[200.48656 182.8677 ]]\n",
      "\n",
      " [[324.3093  155.81769]]\n",
      "\n",
      " [[294.41434 205.88663]]\n",
      "\n",
      " [[219.38225 193.88255]]\n",
      "\n",
      " [[283.41763 211.89986]]\n",
      "\n",
      " [[275.382   201.93155]]\n",
      "\n",
      " [[309.29684 302.96213]]\n",
      "\n",
      " [[246.36252 218.97653]]\n",
      "\n",
      " [[309.38214 194.89478]]\n",
      "\n",
      " [[277.4676  219.90648]]\n",
      "\n",
      " [[282.3381  238.0033 ]]]Here \n",
      " \n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]Here \n",
      " \n",
      "[[293.25668 140.8232 ]\n",
      " [270.34924 143.85898]\n",
      " [255.42058 153.94127]\n",
      " [164.41548 178.97842]\n",
      " [284.3657  230.99585]\n",
      " [258.3537  145.85437]\n",
      " [247.33624 147.91739]\n",
      " [204.41205 195.91687]\n",
      " [278.43625 179.90427]\n",
      " [255.3555  197.93575]\n",
      " [215.43845 237.94972]\n",
      " [269.39868 184.83138]\n",
      " [270.4101  191.85257]\n",
      " [275.31274 138.87344]\n",
      " [296.33286 188.87415]\n",
      " [211.23651 172.92563]\n",
      " [276.42566 211.93138]\n",
      " [284.30203 141.84187]\n",
      " [301.378   201.91818]\n",
      " [312.3365  148.87537]\n",
      " [233.21907 161.94226]\n",
      " [255.34962 190.94832]\n",
      " [309.32968 185.88972]\n",
      " [200.48656 182.8677 ]\n",
      " [324.3093  155.81769]\n",
      " [294.41434 205.88663]\n",
      " [219.38225 193.88255]\n",
      " [283.41763 211.89986]\n",
      " [275.382   201.93155]\n",
      " [309.29684 302.96213]\n",
      " [246.36252 218.97653]\n",
      " [309.38214 194.89478]\n",
      " [277.4676  219.90648]\n",
      " [282.3381  238.0033 ]]Here \n",
      " \n",
      "[293.25668 140.8232 ]\n",
      "(34, 1, 2) (480, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1911: error: (-215:Assertion failed) ((map1.type() == CV_32FC2 || map1.type() == CV_16SC2) && map2.empty()) || (map1.type() == CV_32FC1 && map2.type() == CV_32FC1) in function 'remap'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(p0\u001b[38;5;241m.\u001b[39mshape,mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 83\u001b[0m warped_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43mp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# New points from optical flow\u001b[39;49;00m\n\u001b[1;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_LINEAR\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Threshold to maintain binary mask\u001b[39;00m\n\u001b[1;32m     90\u001b[0m warped_mask \u001b[38;5;241m=\u001b[39m (warped_mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m127\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1911: error: (-215:Assertion failed) ((map1.type() == CV_32FC2 || map1.type() == CV_16SC2) && map2.empty()) || (map1.type() == CV_32FC1 && map2.type() == CV_32FC1) in function 'remap'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# === INPUT ===\n",
    "video_path = \"sample1.mp4\"\n",
    "bounding_box_df = pd.read_csv('YCBvideo/data/0001/000001-box.txt',sep=' ',header=None)\n",
    "label_frame = cv2.imread('YCBvideo/data/0001/000001-label.png',cv.IMREAD_GRAYSCALE)\n",
    "df = bounding_box_df.iloc[0]\n",
    "padding = 0\n",
    "x_min ,x_max ,y_min, y_max = int(df[1])+padding,int(df[2])+padding,int(df[3])+padding,int(df[4]+padding)\n",
    "x_min ,x_max ,y_min, y_max\n",
    "\n",
    "# === PARAMETERS ===\n",
    "feature_params = dict(maxCorners=200, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=5,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# === INITIALIZATION ===\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Mask for features only inside the initial bounding box\n",
    "mask = np.zeros_like(old_gray)\n",
    "print(mask.shape,label_frame.shape)\n",
    "mask[label_frame==2] = 255\n",
    "print(np.unique(mask))\n",
    "# Detect initial features to track\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=mask, **feature_params)\n",
    "\n",
    "# Create image for drawing optical flow tracks\n",
    "mask_lines = np.zeros_like(old_frame)\n",
    "pu= True\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        # Draw the tracks\n",
    "        # if pu:\n",
    "        #     pu= False\n",
    "        #     print(p1,st,good_new,sep='\\n \\n')\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            if pu:\n",
    "                pu= False\n",
    "                print(p1,st,good_new,new,sep='Here \\n \\n')\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            # cv2.line(mask_lines, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (int(a), int(b)), 3, (0, 0, 255), -1)\n",
    "\n",
    "        # if len(good_new) > 0:\n",
    "        #     # Get all x and y coordinates of tracked points\n",
    "        #     x_coords = good_new[:, 0]\n",
    "        #     y_coords = good_new[:, 1]\n",
    "        #     x_min,y_min,x_max,y_max = np.min(x_coords),np.min(y_coords),np.max(x_coords),np.max(y_coords)\n",
    "        #     h,w = y_max-y_min,x_max-x_min\n",
    "        #     padding =50\n",
    "        #     # Compute new bounding box\n",
    "        #     new_x_min = int(x_min -w)\n",
    "        #     new_x_max = int(x_max +w)\n",
    "        #     new_y_min = int(y_min -h)\n",
    "        #     new_y_max = int(y_max + h)\n",
    "            \n",
    "        #     # Draw updated bounding box\n",
    "        #     cv2.rectangle(frame, (new_x_min, new_y_min), \n",
    "        #                 (new_x_max, new_y_max), (255, 0, 0), 2)\n",
    "        \n",
    "        frame_count = 10\n",
    "        print(p0.shape,mask.shape)\n",
    "        warped_mask = cv2.remap(\n",
    "        mask, \n",
    "        p1.reshape(-1, 2).astype(np.float16),  # New points from optical flow\n",
    "        None, \n",
    "        interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "        # Threshold to maintain binary mask\n",
    "        warped_mask = (warped_mask > 127).astype(np.uint8) * 255\n",
    "        # After optical flow computation:\n",
    "        if frame_count % 10 == 0:  # Re-initialize every 10 frames\n",
    "            p0 = cv2.goodFeaturesToTrack(frame_gray, mask=warped_mask, **feature_params)\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # Update previous frame and points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    # Overlay lines on the current frame\n",
    "    output = cv2.add(frame, mask_lines)\n",
    "    cv2.imshow('Optical Flow Tracking', output)\n",
    "\n",
    "    if cv2.waitKey(27) & 0xFF == ord('q'):  # Press ESC to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialization (keep existing code)\n",
    "bounding_box_df = pd.read_csv('YCBvideo/data/0001/000001-box.txt', sep=' ', header=None)\n",
    "df = bounding_box_df.iloc[0]\n",
    "padding = 0  # Add padding for better feature coverage\n",
    "x_min, x_max, y_min, y_max = int(df[1])+padding, int(df[2])+padding, int(df[3])+padding, int(df[4])+padding\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('sample1.mp4')\n",
    "ret, frame = cap.read()\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialize mask with expanded ROI\n",
    "mask = np.zeros_like(old_gray)\n",
    "mask[y_min:y_max, x_min:x_max] = 255\n",
    "\n",
    "feature_params = dict(\n",
    "    maxCorners=1000,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7\n",
    ")\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=mask, **feature_params)\n",
    "\n",
    "lk_params = dict(\n",
    "    winSize=(25, 25),\n",
    "    maxLevel=3,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.03)\n",
    ")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        \n",
    "        if len(good_new) > 4:\n",
    "            # Create convex hull mask\n",
    "            points = good_new.reshape(-1, 2).astype(np.int32)\n",
    "            hull = cv2.convexHull(points)\n",
    "            \n",
    "            # Create tracking visualization\n",
    "            mask_vis = np.zeros_like(frame)\n",
    "            cv2.fillPoly(mask_vis, [hull], (0, 255, 0))\n",
    "            \n",
    "            # Blend with original frame\n",
    "            output = cv2.addWeighted(frame, 0.7, mask_vis, 0.3, 0)\n",
    "            \n",
    "            # Update previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "            # Optional: Redetect features periodically\n",
    "            if len(good_new) < 20:  # Threshold for feature refresh\n",
    "                p0 = cv2.goodFeaturesToTrack(old_gray, mask=mask_vis[:,:,1], **feature_params)\n",
    "                \n",
    "        cv2.imshow('Object Mask Tracking', output)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 2D array\n",
    "my_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Flatten the array using ravel\n",
    "flattened_array = np.ravel(my_array)\n",
    "\n",
    "print(my_array)\n",
    "print(flattened_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('m',mask)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def optical_flow(video_path,mask_path):\n",
    "    # === PARAMETERS ===\n",
    "    feature_params = dict(maxCorners=4, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "        # === INITIALIZATION ===\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## output initialization\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter('optical_flow_output.mp4',\n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'),  # or use 'XVID' for .avi\n",
    "                      fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Mask for features only inside the initial bounding box\n",
    "    mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
    "    # Detect initial features to track\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=mask, **feature_params)\n",
    "    mask_lines = np.zeros_like(old_frame)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            out.release()\n",
    "            print(\"breaking\")\n",
    "            break\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        if p1 is not None:\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            print(\"In\")\n",
    "            # Draw the tracks\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                cv2.line(mask_lines, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (int(a), int(b)), 3, (0, 0, 255), -1)\n",
    "\n",
    "            # Update previous frame and points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        # Overlay lines on the current frame\n",
    "        output = cv2.add(frame, mask_lines)\n",
    "        out.write(output)\n",
    "        # cv2.imshow('Optical Flow Tracking', output)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:  # Press ESC to break\n",
    "            break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n",
      "breaking\n"
     ]
    }
   ],
   "source": [
    "mask = 'YCBvideo/data/0001/000001-depth.png'\n",
    "optical_flow('sample1.mp4',mask)\n",
    "original_img = 'YCBvideo/data/0001/000001-color.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cv.imread(mask)\n",
    "m[m>0] = 255\n",
    "cv.imshow('m',m)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def modify_array(arr):\n",
    "  \"\"\"\n",
    "  Modifies a 3D numpy array:\n",
    "  - Changes values greater than 0 to 0.\n",
    "  - Changes values equal to 0 to 255.\n",
    "\n",
    "  Args:\n",
    "      arr: The input 3D numpy array.\n",
    "\n",
    "  Returns:\n",
    "      The modified numpy array.\n",
    "  \"\"\"\n",
    "  modified_arr = np.where(arr > 0, 0, arr)\n",
    "  modified_arr = np.where(modified_arr == 0, 255, modified_arr)\n",
    "  return modified_arr\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a 3D numpy array named 'my_array'\n",
    "my_array = np.array([[[1, 2, 0], [0, 3, 4]], [[5, 0, 1], [2, 0, 0]]])\n",
    "modified_array = modify_array(my_array)\n",
    "print(modified_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
